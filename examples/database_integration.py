"""
Database Integration Example

This example demonstrates how to integrate KcMF with real databases
for automatic schema discovery and entity matching.
"""

import sys
import os
import json

# Add src to path
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))

from src.llm_interface import create_llm
from src.schema_matching import create_schema_matcher
from src.entity_matching import create_entity_matcher


def extract_schema_from_dict(table_info):
    """
    Extract schema information from a dictionary representation
    In a real scenario, this would query actual database metadata
    """
    return {
        "database": table_info.get("database", "unknown"),
        "table": table_info.get("table", "unknown"),
        "columns": table_info.get("columns", [])
    }


def simulate_database_extraction():
    """
    Simulate extracting schema from real databases
    In production, you would use SQLAlchemy, psycopg2, pymysql, etc.
    """
    # Simulating extraction from MySQL database
    mysql_db = {
        "database": "legacy_erp",
        "table": "products",
        "columns": [
            {"name": "prod_id", "type": "INT", "description": "Product unique identifier"},
            {"name": "prod_name", "type": "VARCHAR(200)", "description": "Product name"},
            {"name": "unit_price", "type": "DECIMAL(10,2)", "description": "Price per unit"},
            {"name": "stock_qty", "type": "INT", "description": "Current stock quantity"},
            {"name": "supplier_id", "type": "INT", "description": "Supplier reference"},
        ]
    }
    
    # Simulating extraction from PostgreSQL database
    postgres_db = {
        "database": "new_commerce",
        "table": "items",
        "columns": [
            {"name": "item_id", "type": "INTEGER", "description": "Item identifier"},
            {"name": "item_name", "type": "TEXT", "description": "Name of the item"},
            {"name": "price", "type": "NUMERIC", "description": "Item price"},
            {"name": "quantity", "type": "INTEGER", "description": "Available quantity"},
            {"name": "category", "type": "TEXT", "description": "Product category"},
            {"name": "vendor_id", "type": "INTEGER", "description": "Vendor reference"},
        ]
    }
    
    return mysql_db, postgres_db


def generate_etl_mapping(matches, source_table, target_table):
    """
    Generate ETL (Extract, Transform, Load) mapping based on matches
    """
    print("\n" + "=" * 60)
    print("ETL MAPPING CONFIGURATION")
    print("=" * 60)
    print(f"\nSource: {source_table}")
    print(f"Target: {target_table}\n")
    
    mapping = {}
    for match in matches:
        source_col = match['source_column']['name']
        target_col = match['target_column']['name']
        confidence = match['confidence']
        
        mapping[target_col] = {
            "source": source_col,
            "confidence": confidence,
            "transform": None  # Add transformation logic if needed
        }
        
        print(f"✓ {target_col:20s} ← {source_col:20s} ({confidence:.1%} confident)")
    
    return mapping


def generate_sql_migration(matches, source_table, target_table):
    """
    Generate SQL statements for data migration
    """
    print("\n" + "=" * 60)
    print("GENERATED SQL MIGRATION SCRIPT")
    print("=" * 60)
    print()
    
    # Extract column mappings
    source_cols = []
    target_cols = []
    
    for match in matches:
        if match['confidence'] >= 0.7:  # Only use high-confidence matches
            source_cols.append(match['source_column']['name'])
            target_cols.append(match['target_column']['name'])
    
    # Generate INSERT ... SELECT statement
    sql = f"""-- Migration script generated by KcMF
-- Source: {source_table}
-- Target: {target_table}

INSERT INTO {target_table} (
    {',\n    '.join(target_cols)}
)
SELECT
    {',\n    '.join(source_cols)}
FROM {source_table};

-- Note: Review and test this script before running in production!
-- Add WHERE clauses, data transformations, and error handling as needed.
"""
    
    print(sql)
    return sql


def extract_entities_from_table():
    """
    Simulate extracting entity records from database tables
    """
    # Simulating customer records from different sources
    source_a_customers = [
        {
            "customer_id": "1001",
            "name": "Acme Corporation",
            "address": "123 Main St, New York, NY",
            "phone": "+1-212-555-0100",
            "email": "contact@acme.com"
        },
        {
            "customer_id": "1002",
            "name": "TechStart Inc",
            "address": "456 Tech Ave, San Francisco, CA",
            "phone": "+1-415-555-0200",
            "email": "info@techstart.com"
        }
    ]
    
    source_b_customers = [
        {
            "client_id": "C001",
            "company_name": "ACME Corp.",
            "location": "123 Main Street, NYC",
            "contact_phone": "212-555-0100",
            "contact_email": "contact@acme.com"
        },
        {
            "client_id": "C002",
            "company_name": "TechStart Incorporated",
            "location": "456 Technology Avenue, SF, California",
            "contact_phone": "(415) 555-0200",
            "contact_email": "info@techstart.com"
        },
        {
            "client_id": "C003",
            "company_name": "Global Industries",
            "location": "789 Business Blvd, Chicago, IL",
            "contact_phone": "+1-312-555-0300",
            "contact_email": "hello@globalind.com"
        }
    ]
    
    return source_a_customers, source_b_customers


def find_matching_entities(entities_a, entities_b, matcher):
    """
    Find matching entities between two lists
    """
    matches_found = []
    
    print("\n" + "=" * 60)
    print("ENTITY MATCHING RESULTS")
    print("=" * 60)
    print()
    
    for entity_a in entities_a:
        best_match = None
        best_confidence = 0
        
        for entity_b in entities_b:
            result = matcher.match(entity_a, entity_b, context="Customer/Client records")
            
            if result['is_match'] and result['confidence'] > best_confidence:
                best_match = entity_b
                best_confidence = result['confidence']
        
        if best_match:
            matches_found.append({
                'entity_a': entity_a,
                'entity_b': best_match,
                'confidence': best_confidence
            })
            
            print(f"MATCH FOUND ({best_confidence:.1%} confidence):")
            print(f"  Source A: {entity_a.get('name', entity_a.get('customer_id'))}")
            print(f"  Source B: {best_match.get('company_name', best_match.get('client_id'))}")
            print()
    
    # Find unmatched entities from B
    matched_b_ids = [m['entity_b'].get('client_id') for m in matches_found]
    unmatched_b = [e for e in entities_b if e.get('client_id') not in matched_b_ids]
    
    if unmatched_b:
        print(f"UNMATCHED ENTITIES IN SOURCE B: {len(unmatched_b)}")
        for entity in unmatched_b:
            print(f"  - {entity.get('company_name', entity.get('client_id'))}")
        print()
    
    return matches_found


def main():
    """Main execution flow for database integration"""
    
    print("=" * 60)
    print("KcMF Database Integration Example")
    print("=" * 60)
    print()
    print("This example demonstrates:")
    print("  1. Schema extraction and matching")
    print("  2. Entity deduplication across databases")
    print("  3. ETL mapping generation")
    print("  4. SQL script generation")
    print()
    
    # Check for API key
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        print("⚠️  WARNING: No API key found!")
        print("Set OPENAI_API_KEY environment variable to run this example.")
        print()
        print("For demonstration purposes, showing the workflow structure...")
        demo_mode = True
    else:
        demo_mode = False
    
    # Initialize LLM
    llm = create_llm(provider="openai", api_key=api_key, temperature=0.3)
    
    # ==========================================
    # PART 1: Schema Matching
    # ==========================================
    print("\n" + "=" * 60)
    print("PART 1: SCHEMA MATCHING")
    print("=" * 60)
    
    # Simulate extracting schemas from databases
    mysql_schema, postgres_schema = simulate_database_extraction()
    
    print(f"\nExtracted Schema from MySQL:")
    print(f"  Database: {mysql_schema['database']}")
    print(f"  Table: {mysql_schema['table']}")
    print(f"  Columns: {len(mysql_schema['columns'])}")
    
    print(f"\nExtracted Schema from PostgreSQL:")
    print(f"  Database: {postgres_schema['database']}")
    print(f"  Table: {postgres_schema['table']}")
    print(f"  Columns: {len(postgres_schema['columns'])}")
    
    if not demo_mode:
        # Perform schema matching
        matcher = create_schema_matcher(llm, similarity_threshold=0.7)
        
        print("\nPerforming schema matching...")
        matches = matcher.match(
            mysql_schema,
            postgres_schema,
            context="Product/Item inventory databases"
        )
        
        # Generate ETL mapping
        mapping = generate_etl_mapping(
            matches,
            f"{mysql_schema['database']}.{mysql_schema['table']}",
            f"{postgres_schema['database']}.{postgres_schema['table']}"
        )
        
        # Generate SQL migration script
        sql_script = generate_sql_migration(
            matches,
            mysql_schema['table'],
            postgres_schema['table']
        )
        
        # Save mapping to file
        mapping_file = "/tmp/etl_mapping.json"
        with open(mapping_file, 'w') as f:
            json.dump(mapping, f, indent=2)
        print(f"\n✓ ETL mapping saved to: {mapping_file}")
        
        # Save SQL to file
        sql_file = "/tmp/migration.sql"
        with open(sql_file, 'w') as f:
            f.write(sql_script)
        print(f"✓ SQL script saved to: {sql_file}")
    
    else:
        print("\n[DEMO MODE] Would perform schema matching and generate:")
        print("  - ETL mapping configuration")
        print("  - SQL migration scripts")
        print("  - Data transformation rules")
    
    # ==========================================
    # PART 2: Entity Matching
    # ==========================================
    print("\n" + "=" * 60)
    print("PART 2: ENTITY MATCHING AND DEDUPLICATION")
    print("=" * 60)
    
    # Extract entity records
    source_a, source_b = extract_entities_from_table()
    
    print(f"\nExtracted {len(source_a)} entities from Source A")
    print(f"Extracted {len(source_b)} entities from Source B")
    
    if not demo_mode:
        # Perform entity matching
        entity_matcher = create_entity_matcher(llm, match_threshold=0.8)
        
        print("\nFinding matching entities across sources...")
        matched_entities = find_matching_entities(source_a, source_b, entity_matcher)
        
        print(f"\n✓ Found {len(matched_entities)} matching entity pairs")
        
        # Generate deduplication report
        print("\nDEDUPLICATION SUMMARY:")
        print(f"  Total unique entities: {len(source_a) + len(source_b) - len(matched_entities)}")
        print(f"  Duplicates found: {len(matched_entities)}")
        print(f"  Deduplication rate: {len(matched_entities)/(len(source_a) + len(source_b)):.1%}")
    
    else:
        print("\n[DEMO MODE] Would perform entity matching and identify:")
        print("  - Duplicate customer records")
        print("  - Entities to merge")
        print("  - Master data creation")
    
    # ==========================================
    # Summary
    # ==========================================
    print("\n" + "=" * 60)
    print("INTEGRATION COMPLETE")
    print("=" * 60)
    print()
    print("Next steps for production deployment:")
    print("  1. Connect to real databases using SQLAlchemy")
    print("  2. Implement incremental processing for large datasets")
    print("  3. Add data validation and quality checks")
    print("  4. Set up monitoring and alerting")
    print("  5. Create backup and rollback procedures")
    print()
    print("For production code, see: docs/DEPLOYMENT.md")


if __name__ == "__main__":
    main()
