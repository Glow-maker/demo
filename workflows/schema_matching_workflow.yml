app:
  description: KcMFæ¨¡å¼åŒ¹é…å·¥ä½œæµ - è‡ªåŠ¨è¯†åˆ«ä¸åŒæ•°æ®æºä¹‹é—´çš„å­—æ®µå¯¹åº”å…³ç³»
  icon: ğŸ”„
  icon_background: '#E3F2FD'
  mode: workflow
  name: kcmf_schema_matching
  use_icon_as_answer_icon: false

kind: app
version: 0.4.0

workflow:
  conversation_variables: []
  environment_variables: []
  
  features:
    retriever_resource:
      enabled: false
    sensitive_word_avoidance:
      enabled: false
    speech_to_text:
      enabled: false
    suggested_questions: []
    suggested_questions_after_answer:
      enabled: false
    text_to_speech:
      enabled: false
  
  graph:
    edges:
      - data:
          isInIteration: false
          isInLoop: false
          sourceType: start
          targetType: llm
        id: start-llm-1
        source: start
        sourceHandle: source
        target: llm-1
        targetHandle: target
        type: custom
      
      - data:
          isInIteration: false
          isInLoop: false
          sourceType: llm
          targetType: code
        id: llm-1-code-1
        source: llm-1
        sourceHandle: source
        target: code-1
        targetHandle: target
        type: custom
      
      - data:
          isInIteration: false
          isInLoop: false
          sourceType: code
          targetType: end
        id: code-1-end
        source: code-1
        sourceHandle: source
        target: end
        targetHandle: target
        type: custom
    
    nodes:
      # å¼€å§‹èŠ‚ç‚¹ - è¾“å…¥ä¸¤ä¸ªæ¨¡å¼
      - data:
          title: å¼€å§‹
          type: start
          variables:
            - label: schema_a
              max_length: 5000
              required: true
              type: paragraph
              variable: schema_a
              hint: "ç¬¬ä¸€ä¸ªæ•°æ®åº“æ¨¡å¼ï¼ˆJSONæ ¼å¼ï¼‰"
            - label: schema_b
              max_length: 5000
              required: true
              type: paragraph
              variable: schema_b
              hint: "ç¬¬äºŒä¸ªæ•°æ®åº“æ¨¡å¼ï¼ˆJSONæ ¼å¼ï¼‰"
            - label: context
              max_length: 1000
              required: false
              type: text-input
              variable: context
              hint: "å¯é€‰ï¼šé¢å¤–çš„ä¸Šä¸‹æ–‡ä¿¡æ¯"
        id: start
        position:
          x: 100
          y: 200
        type: custom
      
      # LLMèŠ‚ç‚¹ - æ‰§è¡Œæ¨¡å¼åŒ¹é…
      - data:
          title: æ¨¡å¼åŒ¹é…LLM
          type: llm
          model:
            mode: chat
            name: gpt-4
            provider: openai
            completion_params:
              temperature: 0.3
              max_tokens: 2000
          prompt_template:
            - role: system
              text: |
                ä½ æ˜¯ä¸€ä¸ªæ•°æ®åº“æ¨¡å¼åŒ¹é…ä¸“å®¶ã€‚ä½ çš„ä»»åŠ¡æ˜¯è¯†åˆ«ä¸¤ä¸ªæ•°æ®åº“æ¨¡å¼ä¹‹é—´å­—æ®µçš„å¯¹åº”å…³ç³»ã€‚
                
                è¯·ä»”ç»†åˆ†æä»¥ä¸‹å› ç´ ï¼š
                1. å­—æ®µåç§°çš„è¯­ä¹‰ç›¸ä¼¼æ€§ï¼ˆä¸ä»…ä»…æ˜¯å­—é¢ç›¸ä¼¼ï¼‰
                2. æ•°æ®ç±»å‹çš„å…¼å®¹æ€§
                3. å­—æ®µæè¿°å’Œå«ä¹‰
                4. ä¸Šä¸‹æ–‡ä¿¡æ¯
                
                å¯¹äºæ¯ä¸ªåŒ¹é…ï¼Œè¯„ä¼°ç½®ä¿¡åº¦ï¼ˆ0-1ä¹‹é—´çš„å°æ•°ï¼‰ï¼š
                - 0.9-1.0: éå¸¸ç¡®å®šçš„åŒ¹é…
                - 0.7-0.9: å¯èƒ½çš„åŒ¹é…
                - 0.5-0.7: ä¸å¤ªç¡®å®š
                - <0.5: ä¸æ¨è
                
                ä»¥JSONæ ¼å¼è¿”å›ç»“æœï¼Œæ ¼å¼å¦‚ä¸‹ï¼š
                {
                  "matches": [
                    {
                      "source_field": "å­—æ®µå",
                      "target_field": "å­—æ®µå",
                      "confidence": 0.95,
                      "reasoning": "åŒ¹é…åŸå› è¯´æ˜"
                    }
                  ]
                }
            
            - role: user
              text: |
                æ¨¡å¼Aï¼š
                {{#start.schema_a#}}
                
                æ¨¡å¼Bï¼š
                {{#start.schema_b#}}
                
                {% if start.context %}
                é¢å¤–ä¸Šä¸‹æ–‡ï¼š
                {{#start.context#}}
                {% endif %}
                
                è¯·è¯†åˆ«è¿™ä¸¤ä¸ªæ¨¡å¼ä¹‹é—´çš„å­—æ®µå¯¹åº”å…³ç³»ã€‚
        id: llm-1
        position:
          x: 400
          y: 200
        type: custom
      
      # ä»£ç èŠ‚ç‚¹ - è§£æå’Œæ ¼å¼åŒ–ç»“æœ
      - data:
          title: ç»“æœå¤„ç†
          type: code
          code_language: python3
          code: |
            import json
            import re
            
            def main(llm_response: str) -> dict:
                """è§£æLLMå“åº”å¹¶æ ¼å¼åŒ–ç»“æœ"""
                
                # æå–JSON
                json_match = re.search(r'```json\s*(.*?)\s*```', llm_response, re.DOTALL)
                if json_match:
                    json_str = json_match.group(1)
                else:
                    json_match = re.search(r'\{.*\}', llm_response, re.DOTALL)
                    if json_match:
                        json_str = json_match.group(0)
                    else:
                        return {
                            "success": False,
                            "error": "æ— æ³•ä»å“åº”ä¸­æå–JSON",
                            "raw_response": llm_response
                        }
                
                try:
                    result = json.loads(json_str)
                    matches = result.get('matches', [])
                    
                    # è¿‡æ»¤ä½ç½®ä¿¡åº¦åŒ¹é…
                    high_confidence_matches = [
                        m for m in matches 
                        if m.get('confidence', 0) >= 0.7
                    ]
                    
                    # ç”Ÿæˆæ‘˜è¦
                    summary = f"æ‰¾åˆ° {len(matches)} ä¸ªæ½œåœ¨åŒ¹é…ï¼Œå…¶ä¸­ {len(high_confidence_matches)} ä¸ªé«˜ç½®ä¿¡åº¦åŒ¹é…"
                    
                    return {
                        "success": True,
                        "total_matches": len(matches),
                        "high_confidence_matches": len(high_confidence_matches),
                        "matches": matches,
                        "summary": summary,
                        "formatted_output": json.dumps(matches, ensure_ascii=False, indent=2)
                    }
                
                except json.JSONDecodeError as e:
                    return {
                        "success": False,
                        "error": f"JSONè§£æé”™è¯¯: {str(e)}",
                        "raw_response": llm_response
                    }
          variables:
            - value_selector:
                - llm-1
                - text
              value_type: string
              variable: llm_response
          outputs:
            success:
              type: string
            total_matches:
              type: number
            high_confidence_matches:
              type: number
            matches:
              type: array[object]
            summary:
              type: string
            formatted_output:
              type: string
            error:
              type: string
            raw_response:
              type: string
        id: code-1
        position:
          x: 700
          y: 200
        type: custom
      
      # ç»“æŸèŠ‚ç‚¹ - è¾“å‡ºç»“æœ
      - data:
          title: åŒ¹é…ç»“æœ
          type: end
          outputs:
            - value_selector:
                - code-1
                - summary
              value_type: string
              variable: summary
            - value_selector:
                - code-1
                - formatted_output
              value_type: string
              variable: matches
            - value_selector:
                - code-1
                - total_matches
              value_type: number
              variable: total_matches
            - value_selector:
                - code-1
                - high_confidence_matches
              value_type: number
              variable: high_confidence_matches
        id: end
        position:
          x: 1000
          y: 200
        type: custom
