#!/usr/bin/env python3
"""
ç»“æœåˆ†æå·¥å…·

ç”¨äºåˆ†æ RAG è’¸é¦æ‰¹é‡å¤„ç†çš„ç»“æœæ–‡ä»¶ï¼Œç”Ÿæˆç»Ÿè®¡æŠ¥å‘Šã€‚

Usage:
    python analyze_results.py results.jsonl
"""

import sys
import json
from typing import Dict, List
from collections import Counter


def analyze_results(filepath: str) -> Dict:
    """åˆ†æç»“æœæ–‡ä»¶å¹¶ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š"""
    
    stats = {
        "total": 0,
        "success": 0,
        "failed": 0,
        "quality_scores": [],
        "quality_levels": Counter(),
        "query_validity": Counter(),
        "query_classes": Counter(),
        "answer_lengths": [],
        "errors": Counter()
    }
    
    with open(filepath, 'r', encoding='utf-8') as f:
        for line in f:
            try:
                item = json.loads(line.strip())
                stats["total"] += 1
                
                status = item.get("status", "unknown")
                if status == "success":
                    stats["success"] += 1
                    
                    # è´¨é‡åˆ†æ•°
                    score = item.get("quality_score", 0)
                    if score:
                        stats["quality_scores"].append(score)
                    
                    # è´¨é‡ç­‰çº§
                    level = item.get("quality_level", "unknown")
                    stats["quality_levels"][level] += 1
                    
                    # é—®é¢˜æœ‰æ•ˆæ€§
                    is_valid = item.get("query_is_valid", "unknown")
                    stats["query_validity"][is_valid] += 1
                    
                    # é—®é¢˜åˆ†ç±»
                    class_name = item.get("query_class_name", "unknown")
                    if class_name:
                        stats["query_classes"][class_name] += 1
                    
                    # ç­”æ¡ˆé•¿åº¦
                    answer = item.get("answer", "")
                    if answer:
                        stats["answer_lengths"].append(len(answer))
                else:
                    stats["failed"] += 1
                    error = item.get("error", "unknown")
                    stats["errors"][error] += 1
                    
            except json.JSONDecodeError as e:
                print(f"Warning: Invalid JSON line - {e}", file=sys.stderr)
                continue
    
    return stats


def print_report(stats: Dict):
    """æ‰“å°ç»Ÿè®¡æŠ¥å‘Š"""
    print("=" * 70)
    print("RAG è’¸é¦æ‰¹é‡å¤„ç†ç»“æœåˆ†ææŠ¥å‘Š")
    print("=" * 70)
    print()
    
    # æ€»ä½“ç»Ÿè®¡
    print("ğŸ“Š æ€»ä½“ç»Ÿè®¡")
    print("-" * 70)
    print(f"æ€»å¤„ç†æ•°é‡: {stats['total']}")
    print(f"æˆåŠŸæ•°é‡: {stats['success']} ({stats['success']/max(stats['total'],1)*100:.1f}%)")
    print(f"å¤±è´¥æ•°é‡: {stats['failed']} ({stats['failed']/max(stats['total'],1)*100:.1f}%)")
    print()
    
    if stats['success'] > 0:
        # è´¨é‡åˆ†æ•°ç»Ÿè®¡
        print("ğŸ¯ è´¨é‡åˆ†æ•°ç»Ÿè®¡")
        print("-" * 70)
        scores = stats['quality_scores']
        if scores:
            print(f"å¹³å‡åˆ†: {sum(scores)/len(scores):.2f}")
            print(f"æœ€é«˜åˆ†: {max(scores):.2f}")
            print(f"æœ€ä½åˆ†: {min(scores):.2f}")
            print(f"ä¸­ä½æ•°: {sorted(scores)[len(scores)//2]:.2f}")
        print()
        
        # è´¨é‡ç­‰çº§åˆ†å¸ƒ
        print("â­ è´¨é‡ç­‰çº§åˆ†å¸ƒ")
        print("-" * 70)
        for level, count in stats['quality_levels'].most_common():
            pct = count / stats['success'] * 100
            print(f"{level:15s}: {count:4d} ({pct:5.1f}%)")
        print()
        
        # é—®é¢˜æœ‰æ•ˆæ€§
        print("âœ… é—®é¢˜æœ‰æ•ˆæ€§")
        print("-" * 70)
        for validity, count in stats['query_validity'].most_common():
            pct = count / stats['success'] * 100
            print(f"{validity:15s}: {count:4d} ({pct:5.1f}%)")
        print()
        
        # é—®é¢˜åˆ†ç±»
        if stats['query_classes']:
            print("ğŸ“‚ é—®é¢˜åˆ†ç±»")
            print("-" * 70)
            for class_name, count in stats['query_classes'].most_common():
                pct = count / stats['success'] * 100
                print(f"{class_name:40s}: {count:4d} ({pct:5.1f}%)")
            print()
        
        # ç­”æ¡ˆé•¿åº¦ç»Ÿè®¡
        print("ğŸ“ ç­”æ¡ˆé•¿åº¦ç»Ÿè®¡")
        print("-" * 70)
        lengths = stats['answer_lengths']
        if lengths:
            print(f"å¹³å‡é•¿åº¦: {sum(lengths)/len(lengths):.0f} å­—ç¬¦")
            print(f"æœ€é•¿: {max(lengths)} å­—ç¬¦")
            print(f"æœ€çŸ­: {min(lengths)} å­—ç¬¦")
        print()
    
    # é”™è¯¯ç»Ÿè®¡
    if stats['failed'] > 0:
        print("âŒ é”™è¯¯ç»Ÿè®¡")
        print("-" * 70)
        for error, count in stats['errors'].most_common():
            pct = count / stats['failed'] * 100
            print(f"{error:30s}: {count:4d} ({pct:5.1f}%)")
        print()
    
    print("=" * 70)


def main():
    """ä¸»å…¥å£"""
    if len(sys.argv) != 2:
        print("Usage: python analyze_results.py <results.jsonl>", file=sys.stderr)
        sys.exit(1)
    
    filepath = sys.argv[1]
    
    try:
        stats = analyze_results(filepath)
        print_report(stats)
    except FileNotFoundError:
        print(f"Error: File not found - {filepath}", file=sys.stderr)
        sys.exit(1)
    except Exception as e:
        print(f"Error: {e}", file=sys.stderr)
        sys.exit(1)


if __name__ == '__main__':
    main()
