# KcMF å®ç°æ•™ç¨‹ï¼šä»å…¥é—¨åˆ°äº§ä¸šåŒ–

æœ¬æ•™ç¨‹å°†å¼•å¯¼æ‚¨é€æ­¥ç†è§£å’Œå®ç° KcMFï¼ˆKnowledge-compliant Framework for Schema and Entity Matching with Fine-tuning-free LLMsï¼‰æ¡†æ¶ã€‚

## ç›®å½•

1. [æ ¸å¿ƒæ¦‚å¿µç†è§£](#1-æ ¸å¿ƒæ¦‚å¿µç†è§£)
2. [ç¯å¢ƒæ­å»º](#2-ç¯å¢ƒæ­å»º)
3. [ç¬¬ä¸€æ­¥ï¼šæ¨¡å¼åŒ¹é…åŸºç¡€](#3-ç¬¬ä¸€æ­¥æ¨¡å¼åŒ¹é…åŸºç¡€)
4. [ç¬¬äºŒæ­¥ï¼šå®ä½“åŒ¹é…åŸºç¡€](#4-ç¬¬äºŒæ­¥å®ä½“åŒ¹é…åŸºç¡€)
5. [ç¬¬ä¸‰æ­¥ï¼šä½¿ç”¨Difyå·¥ä½œæµ](#5-ç¬¬ä¸‰æ­¥ä½¿ç”¨difyå·¥ä½œæµ)
6. [ç¬¬å››æ­¥ï¼šæ•°æ®åº“é›†æˆ](#6-ç¬¬å››æ­¥æ•°æ®åº“é›†æˆ)
7. [ç¬¬äº”æ­¥ï¼šäº§ä¸šåŒ–éƒ¨ç½²](#7-ç¬¬äº”æ­¥äº§ä¸šåŒ–éƒ¨ç½²)
8. [å¸¸è§é—®é¢˜å’Œæœ€ä½³å®è·µ](#8-å¸¸è§é—®é¢˜å’Œæœ€ä½³å®è·µ)

---

## 1. æ ¸å¿ƒæ¦‚å¿µç†è§£

### 1.1 ä»€ä¹ˆæ˜¯æ¨¡å¼åŒ¹é…ï¼ˆSchema Matchingï¼‰ï¼Ÿ

**å®šä¹‰**ï¼šæ¨¡å¼åŒ¹é…æ˜¯è¯†åˆ«ä¸åŒæ•°æ®æºä¸­ç›¸ä¼¼æˆ–ç›¸å…³çš„æ•°æ®ç»“æ„ï¼ˆè¡¨ã€å­—æ®µï¼‰çš„è¿‡ç¨‹ã€‚

**ç°å®åœºæ™¯**ï¼š
```
å…¬å¸Açš„æ•°æ®åº“ï¼š
  customers è¡¨
    - customer_id (å®¢æˆ·ID)
    - customer_name (å®¢æˆ·åç§°)
    - email (é‚®ç®±)

å…¬å¸Bçš„æ•°æ®åº“ï¼š
  clients è¡¨
    - client_id (å®¢æˆ·ID)
    - full_name (å…¨å)
    - email_address (ç”µå­é‚®ä»¶)

æ¨¡å¼åŒ¹é…çš„ä»»åŠ¡ï¼šè¯†åˆ« customer_name â†” full_name, email â†” email_address
```

### 1.2 ä»€ä¹ˆæ˜¯å®ä½“åŒ¹é…ï¼ˆEntity Matchingï¼‰ï¼Ÿ

**å®šä¹‰**ï¼šå®ä½“åŒ¹é…æ˜¯è¯†åˆ«ä¸åŒæ•°æ®æºä¸­ä»£è¡¨åŒä¸€çœŸå®ä¸–ç•Œå¯¹è±¡çš„è®°å½•ã€‚

**ç°å®åœºæ™¯**ï¼š
```
æ•°æ®æºAï¼š
  {name: "Apple Inc.", location: "Cupertino, CA"}

æ•°æ®æºBï¼š
  {name: "è‹¹æœå…¬å¸", location: "ç¾å›½åŠ å·åº“æ¯”è’‚è¯º"}

å®ä½“åŒ¹é…çš„ä»»åŠ¡ï¼šè¯†åˆ«è¿™ä¸¤æ¡è®°å½•æŒ‡å‘åŒä¸€å®¶å…¬å¸
```

### 1.3 ä¸ºä»€ä¹ˆä½¿ç”¨LLMï¼Ÿ

ä¼ ç»Ÿæ–¹æ³•çš„å±€é™ï¼š
- åŸºäºè§„åˆ™ï¼šéš¾ä»¥å¤„ç†å¤æ‚å˜åŒ–
- åŸºäºæœºå™¨å­¦ä¹ ï¼šéœ€è¦å¤§é‡æ ‡æ³¨æ•°æ®å’Œè®­ç»ƒ

LLMçš„ä¼˜åŠ¿ï¼š
- âœ… ç†è§£è¯­ä¹‰ï¼šä¸ä»…çœ‹å­—é¢ç›¸ä¼¼ï¼Œç†è§£å«ä¹‰
- âœ… è·¨è¯­è¨€ï¼šè‡ªåŠ¨å¤„ç†ä¸­è‹±æ–‡ç­‰å¤šè¯­è¨€
- âœ… é›¶å¾®è°ƒï¼šæ— éœ€è®­ç»ƒï¼Œç›´æ¥ä½¿ç”¨
- âœ… æ¨ç†èƒ½åŠ›ï¼šå¯ä»¥è§£é‡ŠåŒ¹é…åŸå› 

---

## 2. ç¯å¢ƒæ­å»º

### 2.1 ç³»ç»Ÿè¦æ±‚

- Python 3.8 æˆ–æ›´é«˜ç‰ˆæœ¬
- 2GB ä»¥ä¸Šå†…å­˜
- ç¨³å®šçš„ç½‘ç»œè¿æ¥ï¼ˆè°ƒç”¨LLM APIï¼‰

### 2.2 å®‰è£…æ­¥éª¤

```bash
# 1. å…‹éš†é¡¹ç›®
git clone <repository-url>
cd demo

# 2. åˆ›å»ºè™šæ‹Ÿç¯å¢ƒï¼ˆæ¨èï¼‰
python -m venv venv
source venv/bin/activate  # Linux/Mac
# æˆ–
venv\Scripts\activate  # Windows

# 3. å®‰è£…ä¾èµ–
pip install -r requirements.txt

# 4. é…ç½®APIå¯†é’¥
cp config/llm_config.yaml.example config/llm_config.yaml
# ç¼–è¾‘ config/llm_config.yamlï¼Œå¡«å…¥ä½ çš„APIå¯†é’¥
```

### 2.3 è·å–LLM APIå¯†é’¥

#### é€‰é¡¹1ï¼šOpenAIï¼ˆæ¨èç”¨äºæµ‹è¯•ï¼‰
1. è®¿é—® https://platform.openai.com/
2. æ³¨å†Œè´¦å·å¹¶å……å€¼
3. åˆ›å»ºAPIå¯†é’¥
4. é…ç½®ç¯å¢ƒå˜é‡ï¼š
   ```bash
   export OPENAI_API_KEY='your-key-here'
   ```

#### é€‰é¡¹2ï¼šé€šä¹‰åƒé—®ï¼ˆæ¨èç”¨äºä¸­æ–‡åœºæ™¯ï¼‰
1. è®¿é—® https://dashscope.aliyun.com/
2. æ³¨å†Œé˜¿é‡Œäº‘è´¦å·
3. å¼€é€šDashScopeæœåŠ¡
4. è·å–APIå¯†é’¥

#### é€‰é¡¹3ï¼šæ™ºè°±AIï¼ˆå›½äº§æ›¿ä»£ï¼‰
1. è®¿é—® https://open.bigmodel.cn/
2. æ³¨å†Œå¹¶è·å–APIå¯†é’¥

---

## 3. ç¬¬ä¸€æ­¥ï¼šæ¨¡å¼åŒ¹é…åŸºç¡€

### 3.1 ç†è§£é—®é¢˜

å‡è®¾æ‚¨æœ‰ä¸¤ä¸ªç³»ç»Ÿï¼š
- **ç³»ç»ŸA**ï¼šè€çš„å®¢æˆ·ç®¡ç†ç³»ç»Ÿ
- **ç³»ç»ŸB**ï¼šæ–°çš„CRMç³»ç»Ÿ

éœ€è¦å°†æ•°æ®ä»Aè¿ç§»åˆ°Bï¼Œä½†å­—æ®µåä¸åŒã€‚

### 3.2 è¿è¡Œç¬¬ä¸€ä¸ªä¾‹å­

```bash
cd examples
python basic_schema_matching.py
```

### 3.3 ç†è§£ä»£ç 

æ‰“å¼€ `examples/basic_schema_matching.py`ï¼Œæ ¸å¿ƒä»£ç ï¼š

```python
# 1. åˆ›å»ºLLMæ¥å£
llm = create_llm(provider="openai", api_key="your-key")

# 2. åˆ›å»ºæ¨¡å¼åŒ¹é…å™¨
matcher = create_schema_matcher(llm, similarity_threshold=0.7)

# 3. å®šä¹‰ä¸¤ä¸ªæ¨¡å¼
schema_a = {
    "table": "customers",
    "columns": ["customer_id", "customer_name", "email"]
}

schema_b = {
    "table": "clients",
    "columns": ["client_id", "full_name", "email_address"]
}

# 4. æ‰§è¡ŒåŒ¹é…
matches = matcher.match(schema_a, schema_b)

# 5. æŸ¥çœ‹ç»“æœ
for match in matches:
    print(f"{match['source_column']['name']} â†’ {match['target_column']['name']}")
    print(f"ç½®ä¿¡åº¦: {match['confidence']:.2%}")
```

### 3.4 è‡ªå·±åŠ¨æ‰‹å®è·µ

**ç»ƒä¹ 1**ï¼šä¿®æ”¹ç¤ºä¾‹ä¸­çš„å­—æ®µåï¼Œçœ‹çœ‹åŒ¹é…ç»“æœå¦‚ä½•å˜åŒ–

```python
# å°è¯•æ›´å¤æ‚çš„ä¾‹å­
schema_a = {
    "columns": [
        {"name": "usr_id", "type": "INT"},
        {"name": "usr_nm", "type": "VARCHAR"},
        {"name": "reg_dt", "type": "DATE"}
    ]
}

schema_b = {
    "columns": [
        {"name": "user_identifier", "type": "INTEGER"},
        {"name": "username", "type": "TEXT"},
        {"name": "registration_date", "type": "TIMESTAMP"}
    ]
}
```

**ç»ƒä¹ 2**ï¼šæ·»åŠ å­—æ®µæè¿°ï¼Œè§‚å¯ŸåŒ¹é…å‡†ç¡®ç‡æå‡

```python
schema_a = {
    "columns": [
        {
            "name": "qty",
            "type": "INT",
            "description": "åº“å­˜æ•°é‡"  # æ·»åŠ æè¿°
        }
    ]
}
```

---

## 4. ç¬¬äºŒæ­¥ï¼šå®ä½“åŒ¹é…åŸºç¡€

### 4.1 ç†è§£åœºæ™¯

**åœºæ™¯**ï¼šå…¬å¸ä»å¤šä¸ªæ¸ é“æ”¶é›†å®¢æˆ·ä¿¡æ¯ï¼Œå­˜åœ¨é‡å¤è®°å½•ã€‚

```
æ¥æºAï¼šå¼ ä¸‰ï¼Œç”µè¯ï¼š138****1234
æ¥æºBï¼šå¼ ä¸‰ï¼Œé‚®ç®±ï¼šzhangsan@example.com
æ¥æºCï¼šZhang Sanï¼Œç”µè¯ï¼š138-****-1234
```

éœ€è¦è¯†åˆ«è¿™äº›æ˜¯åŒä¸€ä¸ªäººã€‚

### 4.2 è¿è¡Œå®ä½“åŒ¹é…ä¾‹å­

```bash
python basic_entity_matching.py
```

### 4.3 ç†è§£æ ¸å¿ƒé€»è¾‘

```python
# 1. åˆ›å»ºå®ä½“åŒ¹é…å™¨
matcher = create_entity_matcher(llm, match_threshold=0.8)

# 2. å®šä¹‰ä¸¤ä¸ªå®ä½“
entity_a = {
    "name": "Apple Inc.",
    "location": "Cupertino, CA"
}

entity_b = {
    "name": "è‹¹æœå…¬å¸",
    "location": "ç¾å›½åŠ å·åº“æ¯”è’‚è¯º"
}

# 3. æ‰§è¡ŒåŒ¹é…
result = matcher.match(entity_a, entity_b)

# 4. åˆ¤æ–­æ˜¯å¦åŒ¹é…
if result['is_match']:
    print(f"åŒ¹é…ï¼ç½®ä¿¡åº¦ï¼š{result['confidence']:.2%}")
else:
    print("ä¸åŒ¹é…")
```

### 4.4 æ‰¹é‡å»é‡

```python
# æ‰¾å‡ºé‡å¤å®ä½“
entities = [
    {"name": "Microsoft", "location": "Redmond"},
    {"name": "å¾®è½¯", "location": "é›·å¾·è’™å¾·"},
    {"name": "Google", "location": "Mountain View"}
]

duplicate_groups = matcher.find_duplicates(entities)
print(f"å‘ç° {len(duplicate_groups)} ç»„é‡å¤")
```

### 4.5 å®è·µç»ƒä¹ 

**ç»ƒä¹ 1**ï¼šå¤„ç†äººå‘˜ä¿¡æ¯å»é‡

```python
employees = [
    {"name": "John Smith", "email": "john.smith@company.com"},
    {"name": "J. Smith", "email": "jsmith@company.com"},
    {"name": "John M. Smith", "email": "john.smith@company.com"}
]

# æ‰¾å‡ºé‡å¤å‘˜å·¥
duplicates = matcher.find_duplicates(employees, context="å‘˜å·¥è®°å½•")
```

**ç»ƒä¹ 2**ï¼šåˆå¹¶é‡å¤è®°å½•

```python
# åˆå¹¶é‡å¤å®ä½“
merged = matcher.merge_entities(duplicates[0], strategy="llm")
print("åˆå¹¶åçš„è®°å½•ï¼š", merged)
```

---

## 5. ç¬¬ä¸‰æ­¥ï¼šä½¿ç”¨Difyå·¥ä½œæµ

### 5.1 ä»€ä¹ˆæ˜¯Difyï¼Ÿ

Difyæ˜¯ä¸€ä¸ªå¯è§†åŒ–çš„LLMåº”ç”¨å¼€å‘å¹³å°ï¼Œæ— éœ€ç¼–ç å³å¯æ„å»ºå·¥ä½œæµã€‚

### 5.2 å¯¼å…¥å·¥ä½œæµ

1. ç™»å½•Difyå¹³å°ï¼šhttps://cloud.dify.ai/
2. åˆ›å»ºæ–°åº”ç”¨ â†’ é€‰æ‹©"å·¥ä½œæµ"
3. å¯¼å…¥é…ç½®æ–‡ä»¶ï¼š`workflows/schema_matching_workflow.yml`

### 5.3 é…ç½®å·¥ä½œæµ

1. **é…ç½®LLMèŠ‚ç‚¹**ï¼š
   - é€‰æ‹©æ¨¡å‹ï¼ˆGPT-4 æˆ– é€šä¹‰åƒé—®ï¼‰
   - å¡«å…¥APIå¯†é’¥

2. **æµ‹è¯•å·¥ä½œæµ**ï¼š
   - è¾“å…¥ç¤ºä¾‹æ•°æ®
   - æŸ¥çœ‹åŒ¹é…ç»“æœ

### 5.4 å·¥ä½œæµä¼˜åŠ¿

ç›¸æ¯”çº¯ä»£ç ï¼š
- âœ… å¯è§†åŒ–è°ƒè¯•
- âœ… æ–¹ä¾¿éæŠ€æœ¯äººå‘˜ä½¿ç”¨
- âœ… æ”¯æŒç‰ˆæœ¬æ§åˆ¶
- âœ… å†…ç½®ç›‘æ§å’Œæ—¥å¿—

### 5.5 è‡ªå®šä¹‰å·¥ä½œæµ

æ‚¨å¯ä»¥åŸºäºæ¨¡æ¿åˆ›å»ºè‡ªå·±çš„å·¥ä½œæµï¼š
- æ·»åŠ æ•°æ®éªŒè¯èŠ‚ç‚¹
- æ·»åŠ äººå·¥å®¡æ ¸ç¯èŠ‚
- é›†æˆåˆ°ç°æœ‰ç³»ç»Ÿ

---

## 6. ç¬¬å››æ­¥ï¼šæ•°æ®åº“é›†æˆ

### 6.1 è¿æ¥çœŸå®æ•°æ®åº“

åˆ›å»ºæ–‡ä»¶ `examples/database_integration.py`ï¼š

```python
from src import create_llm, create_schema_matcher
import sqlalchemy as sa

# 1. è¿æ¥æ•°æ®åº“
engine_a = sa.create_engine('mysql://user:pass@host/db_a')
engine_b = sa.create_engine('postgresql://user:pass@host/db_b')

# 2. æå–æ¨¡å¼ä¿¡æ¯
def extract_schema(engine, table_name):
    inspector = sa.inspect(engine)
    columns = inspector.get_columns(table_name)
    return {
        "table": table_name,
        "columns": [
            {
                "name": col["name"],
                "type": str(col["type"]),
                "nullable": col.get("nullable", True)
            }
            for col in columns
        ]
    }

schema_a = extract_schema(engine_a, 'customers')
schema_b = extract_schema(engine_b, 'clients')

# 3. æ‰§è¡ŒåŒ¹é…
llm = create_llm("openai")
matcher = create_schema_matcher(llm)
matches = matcher.match(schema_a, schema_b)

# 4. ç”Ÿæˆæ˜ å°„SQL
for match in matches:
    source = match['source_column']['name']
    target = match['target_column']['name']
    print(f"{target} = {source}  -- ç½®ä¿¡åº¦: {match['confidence']:.2%}")
```

### 6.2 è‡ªåŠ¨åŒ–æ•°æ®è¿ç§»

```python
# åŸºäºåŒ¹é…ç»“æœç”ŸæˆINSERTè¯­å¥
def generate_migration_sql(matches, source_table, target_table):
    source_cols = [m['source_column']['name'] for m in matches]
    target_cols = [m['target_column']['name'] for m in matches]
    
    sql = f"""
    INSERT INTO {target_table} ({', '.join(target_cols)})
    SELECT {', '.join(source_cols)}
    FROM {source_table}
    """
    return sql
```

---

## 7. ç¬¬äº”æ­¥ï¼šäº§ä¸šåŒ–éƒ¨ç½²

### 7.1 æ€§èƒ½ä¼˜åŒ–

#### æ‰¹é‡å¤„ç†
```python
# ä¸æ¨èï¼šé€ä¸ªå¤„ç†ï¼ˆæ…¢ï¼‰
for entity in entities:
    result = matcher.match(entity, target)

# æ¨èï¼šæ‰¹é‡å¤„ç†ï¼ˆå¿«ï¼‰
results = matcher.match_batch(entity_pairs)
```

#### ç¼“å­˜ç­–ç•¥
```python
from functools import lru_cache

@lru_cache(maxsize=1000)
def cached_match(entity_a_json, entity_b_json):
    entity_a = json.loads(entity_a_json)
    entity_b = json.loads(entity_b_json)
    return matcher.match(entity_a, entity_b)
```

### 7.2 é”™è¯¯å¤„ç†

```python
def robust_match(entity_a, entity_b, max_retries=3):
    for attempt in range(max_retries):
        try:
            return matcher.match(entity_a, entity_b)
        except Exception as e:
            if attempt == max_retries - 1:
                # æœ€åä¸€æ¬¡å°è¯•å¤±è´¥ï¼Œè®°å½•æ—¥å¿—
                logging.error(f"åŒ¹é…å¤±è´¥: {e}")
                return None
            time.sleep(2 ** attempt)  # æŒ‡æ•°é€€é¿
```

### 7.3 ç›‘æ§å’Œæ—¥å¿—

```python
import logging
from datetime import datetime

def match_with_logging(entity_a, entity_b):
    start_time = datetime.now()
    
    try:
        result = matcher.match(entity_a, entity_b)
        duration = (datetime.now() - start_time).total_seconds()
        
        logging.info(f"åŒ¹é…æˆåŠŸï¼Œè€—æ—¶: {duration}s, ç½®ä¿¡åº¦: {result['confidence']}")
        return result
    
    except Exception as e:
        logging.error(f"åŒ¹é…å¤±è´¥: {str(e)}")
        raise
```

### 7.4 APIæœåŠ¡åŒ–

ä½¿ç”¨FastAPIåˆ›å»ºREST APIï¼š

```python
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel

app = FastAPI()

class MatchRequest(BaseModel):
    entity_a: dict
    entity_b: dict
    context: str = None

@app.post("/api/match")
async def match_entities(request: MatchRequest):
    try:
        result = matcher.match(
            request.entity_a,
            request.entity_b,
            request.context
        )
        return result
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# å¯åŠ¨æœåŠ¡
# uvicorn api:app --host 0.0.0.0 --port 8000
```

### 7.5 å®¹å™¨åŒ–éƒ¨ç½²

åˆ›å»º `Dockerfile`ï¼š

```dockerfile
FROM python:3.9-slim

WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt

COPY . .

CMD ["uvicorn", "api:app", "--host", "0.0.0.0", "--port", "8000"]
```

éƒ¨ç½²ï¼š
```bash
docker build -t kcmf-api .
docker run -p 8000:8000 -e OPENAI_API_KEY=your-key kcmf-api
```

---

## 8. å¸¸è§é—®é¢˜å’Œæœ€ä½³å®è·µ

### 8.1 å¦‚ä½•æé«˜åŒ¹é…å‡†ç¡®ç‡ï¼Ÿ

1. **æä¾›æ›´å¤šä¸Šä¸‹æ–‡**
   ```python
   context = "è¿™æ˜¯é‡‘èè¡Œä¸šçš„å®¢æˆ·æ•°æ®ï¼ŒåŒ…å«äº¤æ˜“ä¿¡æ¯"
   matches = matcher.match(schema_a, schema_b, context=context)
   ```

2. **ä½¿ç”¨å­—æ®µæè¿°**
   ```python
   {
       "name": "amt",
       "description": "äº¤æ˜“é‡‘é¢ï¼Œå•ä½ä¸ºå…ƒ"  # å…³é”®ï¼
   }
   ```

3. **é€‰æ‹©åˆé€‚çš„æ¨¡å‹**
   - ä¸­æ–‡åœºæ™¯ï¼šä¼˜å…ˆé€šä¹‰åƒé—®
   - éœ€è¦æ¨ç†ï¼šGPT-4
   - æˆæœ¬æ•æ„Ÿï¼šGPT-3.5

### 8.2 å¦‚ä½•æ§åˆ¶æˆæœ¬ï¼Ÿ

1. **ä½¿ç”¨ç¼“å­˜**
2. **æ‰¹é‡å¤„ç†**
3. **è®¾ç½®åˆç†çš„threshold**ï¼ˆå‡å°‘ä¸å¿…è¦çš„åŒ¹é…ï¼‰
4. **ä½¿ç”¨æ›´ä¾¿å®œçš„æ¨¡å‹åšåˆç­›**

### 8.3 å¦‚ä½•å¤„ç†å¤§è§„æ¨¡æ•°æ®ï¼Ÿ

1. **åˆ†æ‰¹å¤„ç†**
   ```python
   batch_size = 100
   for i in range(0, len(entities), batch_size):
       batch = entities[i:i+batch_size]
       process_batch(batch)
   ```

2. **å¹¶è¡Œå¤„ç†**
   ```python
   from concurrent.futures import ThreadPoolExecutor
   
   with ThreadPoolExecutor(max_workers=4) as executor:
       results = executor.map(process_entity, entities)
   ```

3. **ä½¿ç”¨æ•°æ®åº“ç´¢å¼•**
4. **å®æ–½å¢é‡æ›´æ–°ç­–ç•¥**

### 8.4 å¦‚ä½•ç¡®ä¿æ•°æ®å®‰å…¨ï¼Ÿ

1. **ä¸è¦å°†æ•æ„Ÿæ•°æ®å‘é€åˆ°å…¬å…±API**
2. **è€ƒè™‘ä½¿ç”¨æœ¬åœ°éƒ¨ç½²çš„æ¨¡å‹**
3. **æ•°æ®è„±æ•å¤„ç†**
   ```python
   # åŒ¿ååŒ–ç¤ºä¾‹
   entity = {
       "name": "å¼ ä¸‰",
       "id": "hash(real_id)",  # ä½¿ç”¨å“ˆå¸Œæ›¿ä»£çœŸå®ID
       "phone": "138****1234"   # éƒ¨åˆ†æ©ç 
   }
   ```

### 8.5 é›†æˆåˆ°ç°æœ‰ç³»ç»Ÿ

#### ä½œä¸ºå®šæ—¶ä»»åŠ¡
```python
# cron: æ¯å¤©å‡Œæ™¨2ç‚¹æ‰§è¡Œ
0 2 * * * /path/to/venv/bin/python /path/to/match_script.py
```

#### ä½œä¸ºæ•°æ®æµå¤„ç†
```python
# ä½¿ç”¨Apache Kafka
from kafka import KafkaConsumer, KafkaProducer

consumer = KafkaConsumer('new_entities')
producer = KafkaProducer('matched_entities')

for message in consumer:
    entity = json.loads(message.value)
    result = matcher.match(entity, existing_entities)
    producer.send('matched_entities', json.dumps(result))
```

---

## æ€»ç»“

æ‚¨ç°åœ¨å·²ç»æŒæ¡äº†ï¼š

1. âœ… KcMFæ¡†æ¶çš„æ ¸å¿ƒæ¦‚å¿µ
2. âœ… æ¨¡å¼åŒ¹é…å’Œå®ä½“åŒ¹é…çš„å®ç°
3. âœ… ä½¿ç”¨Difyå·¥ä½œæµç®€åŒ–å¼€å‘
4. âœ… æ•°æ®åº“é›†æˆå’ŒçœŸå®åœºæ™¯åº”ç”¨
5. âœ… äº§ä¸šåŒ–éƒ¨ç½²çš„æœ€ä½³å®è·µ

**ä¸‹ä¸€æ­¥å»ºè®®**ï¼š

1. ä½¿ç”¨æ‚¨è‡ªå·±çš„æ•°æ®æµ‹è¯•
2. æ ¹æ®ä¸šåŠ¡éœ€æ±‚è°ƒæ•´å‚æ•°
3. ç›‘æ§æ€§èƒ½å’Œæˆæœ¬
4. æŒç»­ä¼˜åŒ–åŒ¹é…è§„åˆ™

**éœ€è¦å¸®åŠ©ï¼Ÿ**

- æŸ¥çœ‹ç¤ºä¾‹ä»£ç ï¼š`examples/` ç›®å½•
- å‚è€ƒAPIæ–‡æ¡£ï¼š`docs/API.md`
- æäº¤Issueï¼šGitHub Issues

ç¥æ‚¨çš„æ•°æ®åŒ¹é…é¡¹ç›®æˆåŠŸï¼ğŸ‰
